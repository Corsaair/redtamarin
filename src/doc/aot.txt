Ahead of Time ActionScript Compilation
--------------------------------------

Compiler Overview
-----------------

The AOT compiler (not open source) transforms ABC into LLVM bitcode which can then be linked against the opcode stubs and avmplus to produce a single binary which runs the original program without any need to interpret or JIT. In it's current state you can't enable AOT at the same time as the JIT or interpreter, but this limitation could be removed if necessary.

When implementing the compiler we tried to insulate it from the VM as much as possible to avoid duplicating any logic. For this reason The LLVM bitcode generated by the compiler is very simple but function-rich, continuing one function call per ABC opcode.   The actual implementations of these stubs are written in C++ and in most cases thunk straight to the VM internal implementations. To achieve reasonable performance with such excessive use (abuse?) of function calls we rely heavily on LLVM to  inline lots of relatively small functions.

Handling the ABC
----------------

The goal of the AOT compiler was just to compile the method bodies, there was no reason to change the handling of any other part of the ABC. For this reason the resulting AOT compiled program contains a copy of the original ABC with only one modification: the method bodies are all removed.


Opcode Stubs
------------

Each ABC opcode has a corresponding native implementation written as a templatized c++ function. As an example, here is the signature for  the add instruction:

template<typename rt, typename t1, typename t2> rt abcOP_add(MethodEnv *env, t1 a, t2 b);

The implementations make heavy use of compile-time template-fu so that when specialised instantiations are created the compiler is able to generate the smallest, most optimal code possible. 


Stub Sorting
----------------

Generating a unique function for every possible type-permutation for every opcode results in an object file with around 200,000 functions. Leaving this as a single object file makes linking unacceptably slow, especially for developers accustomed to seeing the results of the modifications to their SWFs a few seconds after making them. To speed the process up we split the object file containing the stubs into ~2000 smaller object files and store this in a standard archive file with an index. The LLVM linker understands how to handle archive files containing bitcode and will use the index to extract only those object files it needs.

We go one step further than this and use statistical data gathered from compiling all of our test apps to symbol sort the object files so that the most frequently used type-permutations of all the opcodes are located contiguously within the object files. This means that of the ~2000 object files within the archive most applications tend to use fewer than ten.

A further optimisation we may implement in the future would have the compiler generate a local cache on the user's machine consisting of the most recently used functions. Incremental compiles would then link against just one object file, only falling back to the normal codepath if the cache wasn't sufficient.

Generating the stub ordering data (AOTStubs.pickle) is currently done on an ad-hoc basis by running a tool over some corpus of representative programs. This tool scans bitcode files for abcOP_* functions and produces a python pickle file containing a map from function name to occurrence count. This information is then fed back into the AOTStubs.py program which generates all of the explicit template instantiations sorted by use and split into ~300 cpp files. Sorting at this stage rather than symbol sorting the actual object files is easier and has no impact on the build time.


Domains
------------

- explain why we punted on this and what we might do in the future


Init Methods
------------

- generated at compile time along with normal methods
- could use the interpreter path (initObj) for quicker compiles at the expense of runtime


Performance
-----------

- point out areas where we beat the jit, and where we need improvement